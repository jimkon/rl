{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\jim\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\jim\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from mountain_car_stds import *\n",
    "import rl_lib\n",
    "from rl_lib.agents.q_learning import DNNQLearningAgent\n",
    "import tensorflow as tf\n",
    "\n",
    "class MCAgent(DNNQLearningAgent):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(state_dims=2,\n",
    "                         actions_num=3,\n",
    "                         hidden_layers=[64, 32],\n",
    "                         activations=[tf.nn.relu, tf.nn.relu],\n",
    "                         drop_out=.3,\n",
    "                         lr=1e-1,\n",
    "                         mapper=rl_lib.utils.UnitMapper(state_low, state_high),\n",
    "                         epsilon_factor=1)\n",
    "        \n",
    "agent = MCAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = run(agent, 1000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_episode(df, episode=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_Q(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_progress(df, agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Q-Learning agent was unable to solve that problem\n",
    "\n",
    "The only difference with the RBF Q-Learning agent is the type of the function approximator. So lets check the ability of the NN to approximate the Q function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "q = pd.read_csv('Q.csv')\n",
    "q.head()\n",
    "\n",
    "states = np.array(q[['state1', 'state2']])\n",
    "action1, action2, action3 = np.array(q['action1']), np.array(q['action2']), np.array(q['action3'])\n",
    "\n",
    "scale = state_high-state_low\n",
    "def scaler(state):\n",
    "    scaled = 2*(state-state_low)/scale-1\n",
    "    return scaled\n",
    "norm_states = np.array([scaler(s) for s in states])\n",
    "\n",
    "x, y = norm_states, np.reshape(action1, (-1, 1))\n",
    "from rl_lib.utils.nets import *\n",
    "net = FullyConnectedDNN(2,\n",
    "                        1,\n",
    "                        hidden_layers=[64, 32],\n",
    "                        activations=[tf.nn.relu, tf.nn.relu],\n",
    "                        drop_out=.1,\n",
    "                        lr=1e-2)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.subplot(1, 3, 1)\n",
    "plot(x, y[:, 0])\n",
    "plt.colorbar(orientation='horizontal')\n",
    "\n",
    "pred = np.array([net.predict(xy) for xy in x])[:, 0]\n",
    "print(pred.shape)\n",
    "plt.subplot(1, 3, 2)\n",
    "plot(x, pred)\n",
    "plt.colorbar(orientation='horizontal')\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "for i in np.random.randint(y.shape[0], size=10000):\n",
    "    net.partial_fit(np.array(x[i]), np.array(y[i]))\n",
    "    \n",
    "pred = np.array([net.predict(xy) for xy in x])[:, 0]\n",
    "print(pred.shape)\n",
    "plt.subplot(1, 3, 3)\n",
    "plot(x, pred)\n",
    "plt.colorbar(orientation='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the deep neural network has the ability to approximate the Q function. That means that the problem lies on the training procedure. \n",
    "\n",
    "Maybe if we use some batching technique (such as minibatching) in order to train the NN more efficiently would solve the problem, but it is not part of this exercise. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
